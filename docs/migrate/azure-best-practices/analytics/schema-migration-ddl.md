---
title: 架構遷移資料定義語言（Ddl）
description: 使用 Azure Synapse 功能來解決高可用性和嚴重損壞修復需求。
author: v-hanki
ms.author: brblanch
ms.date: 07/14/2020
ms.topic: conceptual
ms.service: cloud-adoption-framework
ms.subservice: migrate
ms.openlocfilehash: 50c4233325ffd1663331d0bf36d5fcb4b32cda7b
ms.sourcegitcommit: 9163a60a28ffce78ceb5dc8dc4fa1b83d7f56e6d
ms.translationtype: MT
ms.contentlocale: zh-TW
ms.lasthandoff: 07/17/2020
ms.locfileid: "86451740"
---
<!-- cSpell:ignore DDLs Attunity "Attunity Replicate" "Attunity Visibility" Inmon Denodo Teradata Netezza Wherescape DMVs multinode equi Datometry -->

# <a name="schema-migration-data-definition-languages-ddls"></a>架構遷移資料定義語言（Ddl）

## <a name="design-considerations"></a>設計考量

### <a name="preparation-for-migration"></a>準備進行遷移

準備將現有的資料移轉至 Azure Synapse 分析時，請務必清楚地定義練習的範圍（特別是針對初始的遷移專案）。 在瞭解要遷移的資料庫物件和相關聯的進程之前所花費的時間，將會以降低專案中的投入量和風險來支付紅利。

建立要遷移之資料庫物件的清查。 根據來源平臺，此清查會包含下列部分或所有物件：

- 資料表
- 檢視
- 索引
- 函式
- 預存程序
- 資料散發和分割

您應該透過對來源系統中系統目錄資料表的查詢，取得這些物件的基本資訊（包括資料列計數、實體大小、資料壓縮比例和物件相依性等計量）。 系統中繼資料是這種資訊的最佳來源。 外部檔可能已過時，且不會與自初始執行後已套用至資料結構的變更同步。

您也可以從查詢記錄分析實際的物件使用量，或使用 Microsoft 合作夥伴提供的工具來協助，例如 Attunity 可見度。 可能是因為某些資料表不再用於生產查詢中，所以不需要進行遷移。

資料大小和工作負載資訊（例如，所需的並行層級）很重要，因為它是用來定義適用于 Azure Synapse 分析的適當設定。 瞭解預期的資料和工作負載的未來成長也是個不錯的作法，因為這也會影響建議的目標設定。

使用資料磁片區來估計新目標平臺所需的儲存空間時，請務必瞭解源資料庫上的資料壓縮比率（如果有的話）。 只要採用來源系統上所使用的儲存空間數量，可能會是針對調整大小的錯誤基礎。 您應該可以從監視和中繼資料資訊判斷未壓縮的原始資料大小，以及在目前系統中編制索引、資料複寫、記錄或其他進程的任何額外負荷。

要遷移之資料表的未壓縮原始資料大小，是估計新的目標 Azure Synapse 分析環境中所需儲存體的好起點。

此外，在新的目標平臺中也會有壓縮因素和索引額外負荷，但這些可能會與來源系統不同。 Azure Synapse 分析儲存體定價也包含7天的快照集備份。 相較于現有的環境，這可能會影響所需的整體儲存體成本。

在遷移程式中，資料模型效能微調程式可以保持在最晚的時間，以便在資料倉儲中有實際的資料磁片區時進行。 但是，建議您在程式中稍早可以執行一些效能微調選項。 例如，在 Azure Synapse 分析中，將小型維度資料表定義為複寫資料表，並將大型事實資料表定義為叢集資料行存放區索引，通常是合理的做法。 同樣地，在來源環境中定義的索引，可讓您清楚指出哪些資料行可從新環境中的索引中受益。 在載入前定義資料表時使用這項資訊，將會在稍後的程式中節省時間。

當遷移專案進行時，您可以在 Azure Synapse 分析中測量您自己資料的壓縮比率和索引額外負荷，這是很好的作法。 此量值可讓未來的容量規劃。

在遷移之前，可能只是您現有的資料倉儲，您可以藉由減少複雜性來簡化遷移。 它可能包括：

- 在遷移之前移除或封存未使用的資料表，以避免遷移未使用的資料。 封存到 Azure Blob 儲存體，並將資料定義為外部資料表可能會讓資料保持可用但成本較低。
- 使用資料虛擬化軟體將實體資料超市轉換成虛擬資料超市，以減少您必須遷移的內容。 這項轉換也會改善彈性並降低擁有權總成本，並在遷移期間將其視為現代化。

遷移的其中一個目標，就是變更基礎資料模型，例如，從 Inmon 樣式資料模型移至資料保存庫方法，藉此將倉儲現代化。 這應該決定為準備階段的一部分，而且應該將轉換的策略併入遷移計畫。 在此案例中，建議的方法是先將資料模型遷移至新的平臺，然後在 Azure Synapse 分析中轉換至新的模型，並使用平臺的擴充性和效能特性來執行轉換，而不會影響來源系統。

### <a name="data-model-migration"></a>資料模型遷移

視來源系統的平臺和來源而定，部分或所有元件的資料模型可能已經在星型或雪花式架構形式中。 若是如此，您可以直接將這種方式遷移至 Azure Synapse 分析。 此案例是達到最簡單和最低的風險遷移。 「進行中」遷移也可能是較複雜遷移的第一個階段，包括轉換至新的基礎資料模型，如上述所述。

雖然任何一組關聯式資料表和視圖都可以遷移至 Azure Synapse 分析，但對於大型資料集的分析查詢工作負載而言，星形或雪花式資料模型通常會提供最佳的整體效能。 如果源資料模型尚未採用此形式，可能值得使用遷移程式來重新設計模型。

如果對資料模型進行任何變更，做為遷移專案的一部分，最佳做法是在新的目標環境中執行這些變更，也就是先遷移現有的模型，然後使用 Azure Synapse 分析的強大功能和彈性，將資料轉換成新的模型。 這種方法可將對現有系統的影響降至最低，並使用 Azure Synapse 分析的效能和擴充性，以快速且符合成本效益的方式進行變更。

要遷移的現有系統可能會實作為數個層級（例如，資料內嵌/暫存層、資料倉儲層和報表或資料超市層），其中每個階層都包含許多關聯式資料表和 views。 雖然這些都可以依原樣遷移至 Azure Synapse 分析，但是使用 Azure 生態系統的部分特性和功能，而不是直接遷移所有專案，可能會更符合成本效益且效能更佳。 例如：

- **資料內嵌和暫存：** Azure Blob 儲存體搭配 PolyBase 以快速平行處理資料載入，可用於 ETL/ELT 程式的一部分，而不是關聯式資料表。
- **報告層和資料超市：** Azure Synapse 分析的效能特性可能會讓您不需要實際將匯總資料表具現化，以供報告用途或資料超市之用。 您可以將這些當做 views 實作為核心資料倉儲，或透過協力廠商資料虛擬化層來執行。 在基本層級中，歷程記錄資料的資料移轉程式，可能也會達成增量更新，如下所示：

![新式資料倉儲](../../../_images/analytics/schema-migration-ddl.png)

如果可以使用這些或類似的方法，將會減少要遷移的資料表數目，而且可能會簡化或消除一些進程，進而減少遷移工作負載。 這些方法的適用性取決於個別使用案例，但一般原則是考慮使用 Azure 生態系統的功能和設施，盡可能減少遷移工作負載，並建立符合成本效益的目標環境。 這也適用于其他功能，例如備份/還原和工作流程管理和監視。

另外還有 Microsoft 合作夥伴提供的產品和服務，可協助資料倉儲遷移，而在某些情況下，會將部分程式自動化。 如果現有的系統納入協力廠商 ETL 產品，可能是因為這已經支援 Azure Synapse 分析做為目標環境，而且現有的 ETL 工作流程可能會重新導向至新的目標 Azure SQL 資料倉儲。

### <a name="data-marts-physical-or-virtual"></a>資料超市：實體或虛擬

在舊版資料倉儲環境中，常見的做法是建立一些資料超市結構，以針對特定部門或組織內的商務功能，提供絕佳的自助查詢和報表效能。 因此，資料超市通常是由資料倉儲的子集組成，其中包含資料的匯總版本，可讓使用者透過方便使用的查詢工具（例如 Tableau、MicroStrategy 或 Microsoft Power BI），輕鬆地透過快速的回應時間查詢該資料。 這個表單通常是一種維度資料模型，而資料超市的其中一種用途是以可用的形式公開資料，即使基礎倉儲資料模型不同（例如，資料保存庫）也一樣。 這種方法也稱為三層式模型。

組織中個別業務單位的不同資料超市也可以用來執行穩健的資料安全性制度，方法是只允許使用者存取與他們相關的特定資料超市，以及排除、模糊或匿名敏感性資料。

如果這些資料超市實作為實體資料表，它們就需要額外的儲存體資源來儲存它們，也會定期建立和重新整理它們的額外處理。 這也表示超市中的資料只會是上次重新整理作業的最新狀態，因此可能不適用於高變動性資料儀表板。

隨著相對較便宜的可調整大量平行處理（mpp）架構（例如 Azure Synapse 分析和其固有的效能特性），可能可以提供資料超市功能，而不必將超市具現化為一組實體資料表。 這是藉由使用 Azure Synapse 分析或協力廠商虛擬化產品（例如 Denodo）中的功能，將資料超市透過 SQL views 有效率地虛擬化到主要資料倉儲或透過虛擬化層來達成。 這種方法可簡化或排除額外儲存和匯總處理的需求，並減少要遷移的資料庫物件總數。

這種方法還有另一項可能的優勢。 藉由在虛擬化層內執行匯總和聯結邏輯，並透過虛擬化的視圖呈現外部報告工具，建立這些視圖所需的處理會被推送到資料倉儲中，這通常是在大型資料磁片區上執行諸如聯結和匯總等作業的最佳位置。

選擇執行實體或虛擬資料超市實行的主要驅動程式如下：

- 與實體資料表和相關聯的 ETL 程式相比，虛擬資料超市更具靈活性。
- 降低擁有權總成本，因為虛擬化的執行中有較少的資料存放區和資料複本。
- 消除 ETL 作業，以在虛擬化環境中遷移和簡化 dw 架構。
- 效能：過去的實體資料超市已經更具效能，雖然虛擬化產品現在正在實行智慧型快取技術來減輕此問題

資料虛擬化也可以在遷移專案發生時，用來為終端使用者提供一致的資料檢視。

### <a name="data-mapping"></a>資料對應

**Azure Synapse 分析中的主要和完整性條件約束：**

Azure Synapse 分析中目前不會強制執行 Primary key 和 foreign key 條件約束，但的定義 `PRIMARY KEY` 可包含在 `CREATE TABLE` 具有子句的語句中 `NOT ENFORCED` 。 這表示協力廠商報告產品可以使用資料表的中繼資料來瞭解資料模型內的索引鍵，因而產生最有效率的查詢。

**Azure Synapse 分析中的資料類型支援：**

某些舊版資料庫系統支援 Azure Synapse 分析中目前不直接支援的資料類型。 不過，這些資料類型通常可以使用支援的資料類型來儲存資料，或將資料轉換成支援的資料類型來處理。

支援的資料類型的字母清單如下所示：

<!-- TODO: Review format of this list. Are the arguments necessary for this list? -->

<!-- docsTest:disable -->

- `bigint`
- `binary [ (n) ]`
- `bit`
- `char [ (n) ]`
- `date`
- `datetime`
- `datetime2 [ (n) ]`
- `datetimeoffset [ (n) ]`
- `decimal [ (precision [, scale ]) ]`
- `float [ (n) ]`
- `int`
- `money`
- `nchar [ (n) ]`
- `numeric [ (precision [ , scale ]) ]`
- `nvarchar [ (n | MAX) ]`
- `real [ (n) ]`
- `smalldatetime`
- `smallint`
- `smallmoney`
- `time [ (n) ]`
- `tinyint`
- `uniqueidentifier`
- `varbinary [ (n | MAX) ]`
- `varchar [ (n | MAX) ]`

<!-- docsTest:enable -->

下表列出目前不支援的一些常見資料類型，以及將其儲存在 Azure Synapse 分析中的建議方法。 （如需特定環境（例如 Teradata 或 Netezza），請參閱相關檔以取得詳細資訊）。

| **不支援的資料類型** | **因應措施**                                                      |
|-----------------------|-----------------------------------------------------------------|
| `geometry`              | `varbinary`                                                       |
| `geography`             | `varbinary`                                                       |
| `hierarchyid`           | `nvarchar(4000)`                                                  |
| `image`                 | `varbinary`                                                       |
| `text`                  | `varchar`                                                         |
| `ntext`                 | `nvarchar`                                                        |
| `sql_variant`           | 將資料行分割成數個強型別資料行                |
| `table`                 | 轉換成臨時表                                     |
| `timestamp`             | 修改要使用的程式碼和函式 `datetime2` `CURRENT_TIMESTAMP` |
| `xml`                   | `varchar`                                                         |
| 使用者定義型別     | 可能的話，轉換回原生資料類型              |

**可能的資料問題：**

視來源環境而定，在遷移資料時，會發生一些問題：

- 在不同的資料庫產品中處理資料的方式可能會有些許差異 `NULL` ，例如，定序序列和空字元字串的處理。
- `DATE`、 `TIME` 、 `INTERVAL` 、 `TIME ZONE` 資料和相關聯的函式可能會隨著產品而有很大的差異。

請徹底測試這些，以確保目標環境中會達成所需的結果。 遷移練習也可以發現目前屬於現有來源系統的錯誤或不正確的結果。 遷移程式是修正任何異常狀況的絕佳機會。 在 Azure Synapse 分析中定義資料行的最佳作法：在舊版系統中，通常會使用效率不佳的資料類型來尋找指定的資料行，例如， `VARCHAR(20)` 當實際資料值符合 `CHAR(5)` 欄位時，或使用欄位 `INTEGER` 時，如果所有的值都符合欄位，則定義了欄位 `SMALLINT` 。 這可能會導致儲存和查詢效能的效率不佳，尤其是在大型事實資料表中。

遷移練習可以是檢查現有資料定義和合理化資料定義的好時機。 您可以使用 SQL 查詢來尋找最大數值或資料欄位內的最大字元長度，並與資料類型進行比較，藉此進行自動化。 某些協力廠商資料探索或遷移工具也會納入這項功能。

一般來說，最好是將資料表的總定義資料列長度降到最低（例如，針對上述的每個資料行使用最小的資料類型），這樣做會提供最佳的查詢效能。 PolyBase 公用程式是從 Azure Synapse 分析的外部資料表載入的建議方法，可支援 1 MB 的最大定義資料列長度。 對於大於 1 MB 長度的資料列，無法使用 PolyBase 來載入該資料表，必須改為使用 bcp。

針對最有效率的聯結執行，請將聯結兩端使用的資料行定義為相同的資料類型。 如果維度資料表的索引鍵定義為， `SMALLINT` 則使用該維度之事實資料表中對應的參考資料行也應該定義為 `SMALLINT` 。

避免定義具有大型預設大小的字元欄位。 如果欄位內的資料大小上限是50個字元，請使用 `VARCHAR(50)` 。 同樣地， `NVARCHAR` 如果足夠，也不要使用 `VARCHAR` 。 `NVARCHAR`會儲存 Unicode 資料以允許不同的語言字元集，同時 `VARCHAR` 儲存 ASCII 資料並佔用較少的空間。

## <a name="design-recommendations-summary"></a>設計建議摘要

請勿遷移不必要的物件或進程。 在目標 Azure 環境中使用內建功能和函式，以便減少實際要遷移的物件和進程數目。 請考慮使用虛擬化層來減少或排除要遷移的實體資料超市數目，並將處理推送至資料倉儲。

盡可能自動化。 使用來源系統中系統目錄的中繼資料，為目標環境產生 DDL。 可能的話，也會自動產生檔。 Microsoft 合作夥伴（例如 Wherescape）可以提供特殊的工具和服務來協助解決此情況。

在目標平臺上執行任何必要的資料模型變更或資料對應優化。 這些變更可以在 Azure Synapse 分析中更有效率地完成。 這種方法可減少可能已經接近完整容量的來源系統所造成的影響。

## <a name="performance-options"></a>效能選項

本節說明可用於改善給定資料模型效能的 Azure Synapse 分析中可用的功能。

### <a name="general-approach"></a>一般方法

要遷移的資料庫已經使用該平臺上可用的功能進行效能微調，例如索引、資料分割，以及可能的資料散發。 在準備進行遷移時，應該記載這項功能，因為這可能是可在 Azure Synapse Analytics 目標環境中套用的最佳優化指示。

例如，資料表上是否有非唯一的索引，可以表示索引中使用的欄位經常用於篩選、群組或聯結。 這在新的環境中仍為這種情況，因此在選擇要為其編制索引的欄位時，應該考慮這一點。 特定來源平臺（例如 Teradata 和 Netezza）的遷移建議會在個別的檔中詳細說明。

使用目標 Azure Synapse 分析環境的效能和擴充性來試驗不同的效能選項，例如資料散發，以判斷替代方法的最佳選擇（例如，針對大型維度資料表複寫與雜湊散發）。 這並不表示必須從外部來源重載資料。 藉由使用語句來建立具有不同資料分割或散發選項的任何資料表複本，即可快速且輕鬆地測試 Azure Synapse 分析中的替代方法 `CREATE TABLE AS SELECT` 。

利用 Azure 環境所提供的監視工具來瞭解查詢的執行方式，以及可能發生瓶頸的位置。 另外還有協力廠商 Microsoft 合作夥伴提供的工具，可讓您監視儀表板和自動化資源管理與警示。

Azure Synapse 分析中的每個 SQL 作業，以及該查詢所使用的資源（例如記憶體或 CPU）都會記錄到系統資料表中，並提供一系列的動態管理檢視（Dmv），以簡化此資訊的存取。

下列各節說明 Azure 資料倉儲中用來微調查詢效能的主要選項。 現有的環境將包含目標環境中可能優化的相關資訊。

### <a name="temporary-tables"></a>暫存資料表

Azure Synapse 分析支援臨時表，這些資料表只會在其建立所在的會話中顯示、在使用者會話的持續時間記憶體在，而且會在會話結束時自動卸載。

若要建立臨時表，請在資料表名稱前面加上雜湊字元（ `#` ）。 所有一般的索引和散發選項都可以與臨時表搭配使用（請參閱下文）。

臨時表有一些限制：

- 不允許重新命名資料表。
- 不允許臨時表上的 Views 和資料分割。
- 無法變更臨時表上的許可權。

臨時表常用於 ETL/ELT 處理中，在此過程中，會使用暫時性中繼結果做為轉換程式的一部分。

### <a name="table-distribution-options"></a>資料表散發選項

Azure Synapse 分析是大量平行處理（mpp）資料庫系統，可跨多個處理節點平行執行，以達到效能和擴充性。

在多重節點環境中執行 SQL 查詢時，理想的處理案例是平衡工作負載，讓所有節點都有相同數量的資料要處理，同時將必須在節點之間移動以滿足查詢的資料量減到最少（或完全排除）。

在一般分析查詢中，數個數據表（例如，事實資料表和維度資料表之間）和匯總之間經常會有多個聯結，因此可能很難以達成理想的案例。

影響查詢處理的其中一種方式是使用 Azure Synapse 分析內的散發選項，指定每個資料表的個別資料列儲存位置。 例如，如果兩個大型資料表經常聯結在給定的資料行上（例如 `CUSTOMER_ID` ），則在每 `CUSTOMER_ID` 次執行聯結時使用資料行散發這兩個數據表時，就會在相同的處理節點上共置資料，而不需要在節點之間移動資料。 資料表的散發規格定義于 `CREATE TABLE` 語句中。

以下說明可用的散發選項和使用時機的建議。 如有必要，您可以在初始載入之後變更資料表的散發，方法是使用語句來重新建立具有新散發的資料表 `CREATE TABLE AS SELECT` 。

#### <a name="round-robin"></a>循環配置資源

此資料表散發是預設選項，會將資料平均分散到系統中的節點。 這個方法適用于快速載入資料，以及適用于較低量的資料，而且沒有明顯的雜湊候選項，因此通常會用於臨時表做為 ETL 或 ELT 進程的一部分。

#### <a name="hashed"></a>進行

根據套用至使用者定義索引鍵的雜湊演算法（如 `CUSTOMER_ID` 上述範例所示），系統會將資料列指派給雜湊值區，然後將其指派給特定的節點。 因此，所有以相同值散發的資料列雜湊，最後都會出現在相同的處理節點上。

這個方法適用于經常聯結或匯總在指定索引鍵上的大型資料表。 其他要聯結的大型資料表應該盡可能以相同的索引鍵進行雜湊處理。 如果雜湊索引鍵有多個候選項目，請選擇最常聯結的一個。 雜湊資料行不應包含 null，而且通常不是日期，因為有許多查詢會篩選日期）。 如果雜湊的索引鍵是整數值，而不是或，則雜湊通常更有效率 `CHAR` `VARCHAR` 。 此外，也請避免選擇具有高度扭曲值範圍的索引鍵，例如，少量的索引鍵值表示資料列的百分比偏高。

#### <a name="replicated"></a>複寫

選擇 [複寫] 做為資料表的散發選項，將會在每個計算節點上複寫該資料表的完整複本，以供查詢處理之用。

這種方法適用于相對較小的小型資料表（通常小於 2 GB），其相對靜態且經常聯結至較大的資料表（透過同等聯結）。 這些資料表通常是星狀架構中的維度資料表。

### <a name="indexing"></a>編製索引

Azure Synapse 分析包含數個選項，可在大型資料表中編制資料的索引，以減少取得記錄所需的資源和時間：

- 叢集資料行存放區索引
- 叢集索引
- 非叢集索引

針對不會 `HEAP` 從任何索引選項獲益的資料表，也有一個未索引的選項可供呼叫。 使用索引是改良的查詢時間與較長的載入時間，以及更多的儲存空間使用量之間的取捨。 索引通常 `SELECT` `UPDATE` `DELETE` `MERGE` 會在影響少量資料列的大型資料表上加速、和作業，而且索引有助於避免進行完整的資料表掃描。

在資料 `UNIQUE` `PRIMARY KEY` 行上定義或條件約束時，會自動建立索引。

#### <a name="clustered-columnstore-index"></a>叢集資料行存放區索引

這是 Azure Synapse 分析中的預設索引選項，可為大型資料表提供最佳的壓縮和查詢效能。 對於較小的資料表（少於60000000個數據列），這些索引不有效率，因此應該使用堆積選項。 同樣地，如果資料表中的資料是暫時性的（可能是 ETL/ELT 進程的一部分）堆積或臨時表，可能會更有效率。

#### <a name="clustered-index"></a>叢集索引

如果需要根據強式篩選準則，從大型資料表定期抓取單一資料列或少數幾個資料列，叢集索引可能會比叢集資料行存放區索引更有效率。 每個資料表只允許一個叢集索引。 複寫

#### <a name="non-clustered-index"></a>非叢集索引

非叢集索引類似于叢集索引，因為它們可以根據篩選準則來加速單一資料列或少量資料列的抓取。 內部非叢集索引會與資料分開儲存，而且可以在資料表上定義多個非叢集索引。 不過，每個額外的索引都需要更多儲存空間，而且會減少資料插入或載入的輸送量。

#### <a name="heap"></a>堆積

堆積資料表不會產生任何與在資料載入時間建立和維護索引相關聯的額外負荷，因此有助於快速載入暫時性資料（例如，做為 ETL 程式的一部分）。 在這種情況下，快取也可以受益于立即讀取的資料。 堆積資料表也適用于儲存少於60000000個數據列的資料表，因為叢集資料行存放區索引低於該大小。

### <a name="data-partitioning"></a>資料分割

在企業資料倉儲中，事實資料表可以包含許多數十億個數據列和資料分割，這是一種方式，可將這些資料表分割成不同的部分，以減少執行查詢時所處理的資料量，藉此優化這些資料表的維護和查詢。 資料表的資料分割規格定義于 `CREATE TABLE` 語句中。

每個資料表只能有一個欄位用於資料分割，這通常是日期欄位，因為許多查詢會依日期或日期範圍進行篩選。 如有需要，您可以在初始載入後變更資料表的資料分割，方法是使用語句來重新建立具有新散發的資料表 `CREATE TABLE AS SELECT` 。

#### <a name="partitioning-for-query-optimization"></a>查詢優化的資料分割

如果對大型事實資料表的查詢經常依特定資料行進行篩選，則該資料行上的資料分割可能會大幅減少需要處理來執行查詢的資料量。 常見的範例是使用日期欄位，將資料表分割成較小的群組，其中每一個包含一天的資料。 當查詢包含 `WHERE` 篩選日期的子句時，只需要存取符合日期篩選的資料分割。

#### <a name="partitioning-for-table-maintenance-optimization"></a>資料表維護優化的分割

資料倉儲環境中通常會維護詳細事實資料的滾動視窗，例如，銷售交易會回到五年。 藉由在銷售日期進行資料分割，將舊資料移除到滾動時間範圍外會變得更有效率。 卸載最舊的分割區比刪除所有的個別資料列更快，而且使用的資源更少。

### <a name="statistics"></a>統計資料

當查詢提交至 Azure Synapse 分析時，它會先由查詢最佳化工具處理，這會決定要用來有效率地執行查詢的最佳內部方法。 優化工具會根據以成本為基礎的演算法來比較可用的各種查詢執行計畫，而成本估計的精確度則取決於可用的統計資料。 因此，確保統計資料是最新狀態的最佳作法。

在 Azure Synapse 分析中，如果 `AUTO_CREATE_STATISTICS` 選項已開啟，它會觸發統計資料的自動更新。 您也可以透過命令手動建立或更新統計資料 `CREATE STATISTICS` 。

當內容已大幅變更（例如每日更新）時，重新整理統計資料。 這種重新整理可以併入 ETL 進程中。

資料庫中的所有資料表都應該至少在一個資料行上收集統計資料（以確保可供優化工具使用的基本資訊（例如資料列計數和資料表大小）。 其他應收集統計資料的資料行是在 `JOIN` 、 `DISTINCT` 、 `ORDER BY` 和 `GROUP BY` 處理中指定的資料行。

### <a name="workload-management"></a>工作負載管理

Azure Synapse 分析納入了跨混合式工作負載管理資源使用率的完整功能。 為不同的工作負載類型（例如查詢與資料載入）建立資源類別，可協助您管理工作負載，方法是設定同時執行的查詢數目限制，以及指派給每個查詢的計算資源。 記憶體和並行存取之間各有取捨。

- 較小型的資源類別會減少每個查詢的記憶體上限，但會增加並行存取數。
- 較大型資源類別會增加每個查詢的記憶體上限，但會減少並行存取數。

### <a name="performance-recommendations"></a>效能建議

使用任何效能改進方法（例如，索引、資料散發）做為新目標環境中類似量值的候選指示，但在 Azure Synapse 分析中確認它們是必要的。 建立 `COLLECT STATISTICS` ETL/ELT 程式的步驟，以確保統計資料是最新的，或開啟自動建立統計資料。

瞭解 Azure Synapse 分析中可用的微調選項，以及相關聯公用程式的效能特性，例如 PolyBase 以快速平行處理資料載入。 使用這些選項來建立有效率的端對端執行。

使用 Azure 環境的彈性、擴充性和效能，就地執行任何資料模型變更或效能微調選項，以降低對現有來源系統的影響。

瞭解 Azure Synapse 分析中提供的動態管理檢視，以提供整個系統的資源使用量資訊，以及個別查詢的詳細執行資訊。

瞭解 Azure 資源類別並適當地加以配置，以確保能有效率地管理混合的工作負載和平行存取。

請考慮使用虛擬化層作為 Azure Synapse 分析環境的一部分，以從商務使用者和報表工具防護倉儲執行的變更。

研究由協力廠商提供者所提供的遷移工具和服務，例如 Microsoft 遷移、Wherescape 和 Datometry hyper-q 的 Attunity 複寫。 這些工具可以自動化部分的遷移程式，並減少與遷移專案相關的已耗用時間和風險。
